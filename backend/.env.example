# Copy to .env and fill in values
# AI
GEMINI_API_KEY=your_gemini_api_key_here
GROQ_API_KEY=your_groq_api_key_here
# Preferred model (defaults to gemini-2.5-pro if unset)
GEMINI_MODEL=gemini-2.5-flash

# Hugging Face (for image generation)
HF_API_KEY=your_hf_api_key_here
# Optional: override default model (defaults to SDXL base)
# Recommended public models:
# - stabilityai/stable-diffusion-xl-base-1.0 (default)
# - stabilityai/sdxl-turbo (fast, lower fidelity)
# - black-forest-labs/FLUX.1-schnell (fast FLUX)
# - runwayml/stable-diffusion-v1-5 (legacy SD 1.5)
HF_MODEL=black-forest-labs/FLUX.1-dev


# Try additional known models automatically if the configured one is unavailable (default: true)
HF_ALLOW_FALLBACK=true

# If image generation fails, return a readable placeholder SVG instead of a 500 error (default: false)
HF_PLACEHOLDER_ON_FAIL=false

# IMPORTANT: Some models require accepting terms on their Hugging Face page.
# If you receive 403 errors, sign in with the same account as your token,
# open the model page (e.g., https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0),
# click "Agree and access repository", then restart the backend. Alternatively,
# set HF_MODEL to a model you already have access to.

# Optional: return mock responses without calling external API
MOCK_AI=false

# Database (optional for AI-only testing)
# (Legacy) Node server settings below can be ignored when using FastAPI
MONGO_URI=mongodb://127.0.0.1:27017/mindspace

# Server
PORT=5000
DB_URL=sqlite:///backend.db
